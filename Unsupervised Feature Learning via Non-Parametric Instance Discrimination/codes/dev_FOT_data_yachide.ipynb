{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FoT データを、画像検索用のデータセットにサンプリングする。  \n",
    "  \n",
    "#### FoTデータの場所:  \n",
    "/mnt/mnt/nfs/dataset/dev_FOT_data_yachide/Classification_MOVIE  \n",
    "  \n",
    "318029動画ある  \n",
    "1動画およそ1分  \n",
    "10fps  \n",
    "640 x 340  \n",
    "  \n",
    "#### 元データのディレクトリ構成は以下:  \n",
    "Classification_MOVIE  \n",
    "　　　　|- DAYTIME_FINE_JP_HIGHWAY  \n",
    "　　　　|　　　　|-{purpose}_{バージョン}_{トリップ開始時刻}  \n",
    "　　　　|　　　　|　　　　LMOVIE  \n",
    "　　　　|　　　　|　　　　　　|-{動画開始時刻}_{動画中央時刻}_{動画終了時刻}.mp4  \n",
    "　　　　|　　　　|　　　　　　...  \n",
    "　　　　|　　　　...  \n",
    "　　　　|  \n",
    "　　　　|- {DAY/NIGHT}_{WEATHER}_{JAPAN/NA}_{HIGHWAY/NORMAL}  \n",
    "　　　　...       \n",
    "  \n",
    "#### 以下のディレクトリに出力したい:  \n",
    "/mnt/mnt/nfs/home/yasumasa_kobayashi/codes/lemniscate/datasets/data/FoT_yachide  \n",
    "  \n",
    "サンプリング後のディレクトリ構成を以下としたい:  \n",
    "FoT_yachide  \n",
    "　　　　|- train  \n",
    "　　　　|　　　　|-{purpose}_{バージョン}_{トリップ開始時刻}_{動画開始時刻}_{動画中央時刻}_{動画終了時刻}　★  \n",
    "　　　　|　　　　|　　　　|- {purpose}_{バージョン}_{トリップ開始時刻}_{動画開始時刻}_{動画中央時刻}_{動画終了時刻}_train_001.jpeg  \n",
    "　　　　|　　　　|　　　　|- {purpose}_{バージョン}_{トリップ開始時刻}_{動画開始時刻}_{動画中央時刻}_{動画終了時刻}_train_002.jpeg  \n",
    "　　　　|　　　　|　　　　|- {purpose}_{バージョン}_{トリップ開始時刻}_{動画開始時刻}_{動画中央時刻}_{動画終了時刻}_train_{連番3桁}.jpeg    \n",
    "　　　　|　　　　|　　　　...  \n",
    "　　　　|  　　　...\n",
    "　　　　|  \n",
    "　　　　L val  \n",
    "　　　　　　　　|-{purpose}_{バージョン}_{トリップ開始時刻}_{動画開始時刻}_{動画中央時刻}_{動画終了時刻}　★  \n",
    "　　　　　　　　|　　　　|- {purpose}_{バージョン}_{トリップ開始時刻}_{動画開始時刻}_{動画中央時刻}_{動画終了時刻}_val_001.jpeg  \n",
    "　　　　　　　　|　　　　|- {purpose}_{バージョン}_{トリップ開始時刻}_{動画開始時刻}_{動画中央時刻}_{動画終了時刻}_val_002.jpeg  \n",
    "　　　　　　　　|　　　　|- {purpose}_{バージョン}_{トリップ開始時刻}_{動画開始時刻}_{動画中央時刻}_{動画終了時刻}_val_{連番3桁}.jpeg  \n",
    "　　　　　　　　|　　　　...  \n",
    "　　　　  　　　...  \n",
    "  \n",
    "pytorchのfolder instanceで読み込むと、★がクラス(ID)になる i.e. フォルダ直下の画像が同じクラスとして扱われる  \n",
    "  \n",
    "#### サンプリング  \n",
    "- 参考文献(Driving Scene-Retrieval by Example from Large-Scale Data)では、30fps (BDD) → 6fpsにしていた  \n",
    "- とりあえず、1fpsでサンプリングする\n",
    "- どれくらい学習に時間がかかるかを調べるために、3フレーム分投入する\n",
    "    - 多分、resnetの最終出力ｘ３をconcatしているのでは？  \n",
    "    \n",
    "#### ざっくりとしたアルゴリズム  \n",
    "- やりたいこと  \n",
    "1. 動画ごとに、ディレクトリを作成し、動画をサンプリング。jpegとして格納  \n",
    "　　・その際に、trainとvalをわけて格納する  \n",
    "　　・step1としては、先頭3フレームをtrain、次の3フレームをvalにする。(1fpsとする)  \n",
    "　　　・後々、フレーム数でどれくらい検索性能が変わるかを見たい場合は、1フレームずつサンプリングし、コピーするようにする  \n",
    "\n",
    "・globで全データのmp4を取得する  \n",
    "・先頭から  \n",
    "　・ディレクトリを作成(train, val)  \n",
    "　・サンプリングする(train, val)  \n",
    "　・ディレクトリ内に格納する  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318029\n",
      "Thread: 0 started.\n",
      "size:  10000\n",
      "sampling video... 10000\n",
      "Thread: 1 started.\n",
      "size:  10000\n",
      "sampling video... 10000\n",
      "Thread: 2 started.\n",
      "size:  10000\n",
      "sampling video... 10000\n",
      "Thread: 3 started.\n",
      "size:  10000\n",
      "sampling video... 10000\n",
      "Thread: 4 started.\n",
      "size:  10000\n",
      "sampling video... 10000\n",
      "Thread: 5 started.\n",
      "size:  10000\n",
      "sampling video... 10000\n",
      "Thread: 6 started.\n",
      "size:  10000\n",
      "sampling video... 10000\n",
      "Thread: 7 started.\n",
      "size:  10000\n",
      "sampling video... 10000\n",
      "Thread: 8 started.\n",
      "size:  10000\n",
      "sampling video... 10000\n",
      "Thread: 9 started.\n",
      "size:  10000\n",
      "sampling video... 10000\n",
      "Thread: 10 started.\n",
      "size:  10000\n",
      "sampling video... 10000\n",
      "Thread: 11 started.\n",
      "size:  10000\n",
      "sampling video... 10000\n",
      "Thread: 12 started.\n",
      "size:  10000\n",
      "sampling video... 10000\n",
      "Thread: 13 started.\n",
      "size:  10000\n",
      "sampling video... 10000\n",
      "Thread: 14 started.\n",
      "size:  Thread: 15 started.10000\n",
      "sampling video... 10000\n",
      "\n",
      "size:  10000Thread: 16 started.\n",
      "Thread: 17 started.\n",
      "size:  10000\n",
      "sampling video... 10000\n",
      "sampling video... 10000\n",
      "\n",
      "Thread: 18 started.Thread: 19 started.size: \n",
      "size:  10000\n",
      "size:  10000\n",
      "sampling video... 10000\n",
      " 10000\n",
      "sampling video... 10000\n",
      "Thread: 20 started.\n",
      "size:  10000\n",
      "sampling video... 10000\n",
      "\n",
      "sampling video... 10000\n",
      "Thread: 21 started.\n",
      "size:  10000\n",
      "sampling video... 10000\n",
      "Thread: 22 started.\n",
      "size:  10000\n",
      "sampling video... 10000\n",
      "Thread: 23 started.\n",
      "size:  10000Thread: 24 started.\n",
      "size:  10000\n",
      "sampling video... 10000\n",
      "\n",
      "Thread: 25 started.\n",
      "size:  10000sampling video... 10000\n",
      "\n",
      "sampling video... 10000\n",
      "Thread: 26 started.\n",
      "size:  10000\n",
      "sampling video... 10000\n",
      "Thread: 27 started.\n",
      "size:  10000\n",
      "sampling video... 10000\n",
      "Thread: 28 started.Thread: 29 started.\n",
      "size:  10000\n",
      "sampling video... 10000\n",
      "Thread: 30 started.\n",
      "size:  10000\n",
      "sampling video... 10000\n",
      "\n",
      "size: Thread: 31 started.\n",
      "size:   8029\n",
      "10000\n",
      "sampling video... 10000\n",
      "sampling video... 8029\n",
      "Thread: 31 ended.\n",
      "Thread: 19 ended.\n",
      "Thread: 10 ended.\n",
      "Thread: 23 ended.\n",
      "Thread: 17 ended.\n",
      "Thread: 9 ended.\n",
      "Thread: 21 ended.\n",
      "Thread: 8 ended.\n",
      "Thread: 7 ended.\n",
      "Thread: 24 ended.\n",
      "Thread: 28 ended.\n",
      "Thread: 1 ended.\n",
      "Thread: 20 ended.\n",
      "Thread: 26 ended.\n",
      "Thread: 2 ended.\n",
      "Thread: 0 ended.\n",
      "Thread: 3 ended.\n",
      "Thread: 16 ended.\n",
      "Thread: 4 ended.\n",
      "Thread: 6 ended.\n",
      "Thread: 25 ended.\n",
      "Thread: 22 ended.\n",
      "Thread: 30 ended.\n",
      "Thread: 27 ended.\n",
      "Thread: 5 ended.Thread: 13 ended.\n",
      "\n",
      "Thread: 15 ended.\n",
      "Thread: 29 ended.\n",
      "Thread: 14 ended.\n",
      "Thread: 12 ended.\n",
      "Thread: 11 ended.\n",
      "Thread: 18 ended.\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "FoT_directory =  '/mnt/mnt/nfs/dataset/dev_FOT_data_yachide/Classification_MOVIE'\n",
    "list_of_mp4_files = glob.glob(FoT_directory+'/**/**.mp4',recursive=True)\n",
    "print(len(list_of_mp4_files))\n",
    "\n",
    "train_directory = '/mnt/mnt/nfs/home/yasumasa_kobayashi/codes/lemniscate/datasets/data/FoT_yachide/train'\n",
    "val_directory = '/mnt/mnt/nfs/home/yasumasa_kobayashi/codes/lemniscate/datasets/data/FoT_yachide/val'\n",
    "\n",
    "if not os.path.isdir(train_directory):\n",
    "    os.mkdir(train_directory)\n",
    "    os.chmod(train_directory, 0o777)\n",
    "if not os.path.isdir(val_directory):\n",
    "    os.mkdir(val_directory)\n",
    "    os.chmod(val_directory, 0o777)\n",
    "\n",
    "def save_frame_range(video_path, start_frame, end_frame, step_frame, save_path, train=True):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        return\n",
    "    idx=0\n",
    "    for i in range(start_frame, end_frame, step_frame):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            idx+=1\n",
    "            if train:\n",
    "                save_name = save_path+'_train_'+str(idx).zfill(3)+'.jpeg'\n",
    "            else:\n",
    "                save_name = save_path+'_val_'+str(idx).zfill(3)+'.jpeg'\n",
    "            cv2.imwrite(save_name, frame)\n",
    "        else:\n",
    "            return\n",
    "\n",
    "def sample_video_frames(list_of_mp4_files):\n",
    "    print('sampling video...', len(list_of_mp4_files))\n",
    "    for i, mp4_file in enumerate(list_of_mp4_files):\n",
    "    #for i, mp4_file in tqdm(enumerate(list_of_mp4_files)):\n",
    "        #if i==10:\n",
    "        #    break\n",
    "\n",
    "        #ディレクトリを作成\n",
    "        splitted_list = mp4_file.split('/')\n",
    "        name_dir = splitted_list[8]+'_'+splitted_list[10][:-4] #{purpose}_{バージョン}_{トリップ開始時刻}_{動画開始時刻}_{動画中央時刻}_{動画終了時刻}\n",
    "        train_dir = os.path.join(train_directory, name_dir)\n",
    "        val_dir = os.path.join(val_directory, name_dir)\n",
    "        if not os.path.isdir(train_dir):\n",
    "            os.mkdir(train_dir)\n",
    "            os.chmod(train_dir, 0o777)\n",
    "        if not os.path.isdir(val_dir):\n",
    "            os.mkdir(val_dir)\n",
    "            os.chmod(val_dir, 0o777)\n",
    "\n",
    "        #サンプリングをし、ディレクトリに保存する\n",
    "        save_path = os.path.join(train_dir, name_dir) \n",
    "        save_frame_range(mp4_file, 0, 30, 10, save_path, train=True)\n",
    "        save_path = os.path.join(val_dir, name_dir) \n",
    "        save_frame_range(mp4_file, 30, 60, 10, save_path, train=False)\n",
    "    \n",
    "### 並列処理で実行\n",
    "#from multiprocessing import Pool\n",
    "#pool = Pool(processes = 40)\n",
    "#pool.map(sample_video_frames(list_of_mp4_files))\n",
    "#pool.close()\n",
    "\n",
    "import threading\n",
    "\n",
    "class Sampling_Thread(threading.Thread):\n",
    "\n",
    "    def __init__(self, thread_name, list_of_mp4_files):\n",
    "        self.thread_name = str(thread_name)\n",
    "        threading.Thread.__init__(self)\n",
    "        self.list_of_mp4_files = list_of_mp4_files\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.thread_name\n",
    "\n",
    "    def run(self):\n",
    "        print('Thread: %s started.' % self.thread_name)\n",
    "        print('size: ',len(self.list_of_mp4_files))\n",
    "        sample_video_frames(self.list_of_mp4_files)\n",
    "        print('Thread: %s ended.' % self.thread_name)\n",
    "        \n",
    "thread_list = []\n",
    "for i in range(len(list_of_mp4_files)//10000+1):\n",
    "    #print(len(list_of_mp4_files[i*10000:(i+1)*10000]))\n",
    "    _sub = list_of_mp4_files[i*10000:(i+1)*10000]\n",
    "    thread = Sampling_Thread(thread_name=i, list_of_mp4_files=_sub)\n",
    "    thread.start()\n",
    "    thread_list.append(thread)\n",
    "\n",
    "for thread in thread_list:\n",
    "    thread.join()\n",
    "\n",
    "print('finished')\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'mnt', 'mnt', 'nfs', 'dataset', 'dev_FOT_data_yachide', 'Classification_MOVIE', 'DAYTIME_FINE_JP_HIGHWAY', 'ASP_20160830001_1470800158778', 'MOVIE', '1470806999691_1470807029691_1470807059691.mp4']\n",
      "ASP_20160830001_1470800158778_1470806999691_1470807029691_1470807059691\n",
      "ASP_20160830001_1470800158778_1470806999691_1470807029691_1470807059691/ASP_20160830001_1470800158778_1470806999691_1470807029691_1470807059691_train_001.jpeg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "name = '/mnt/mnt/nfs/dataset/dev_FOT_data_yachide/Classification_MOVIE/DAYTIME_FINE_JP_HIGHWAY/ASP_20160830001_1470800158778/MOVIE/1470806999691_1470807029691_1470807059691.mp4'\n",
    "splitted_list = name.split('/')\n",
    "print(splitted_list)\n",
    "name_dir = splitted_list[8]+'_'+splitted_list[10][:-4]\n",
    "print(name_dir)\n",
    "train_save_name = name_dir + '_train_001.jpeg'\n",
    "train_save_name = os.path.join(name_dir, train_save_name)\n",
    "print(train_save_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7951\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "FoT_directory =  '/mnt/mnt/nfs/dataset/dev_FOT_data_yachide/Classification_MOVIE'\n",
    "list_of_mp4_files = glob.glob(FoT_directory+'/**/**.mp4',recursive=True)\n",
    "data_len = len(list_of_mp4_files)\n",
    "_steps = data_len/40\n",
    "i = range(0, data_len, int(_steps+1))\n",
    "print(i[0], i[1])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "8029\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(list_of_mp4_files)//10000+1):\n",
    "    _sub = list_of_mp4_files[i*10000:(i+1)*10000]\n",
    "    print(len(list_of_mp4_files[i*10000:(i+1)*10000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
